<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>koori</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="数据处理 LIMO：2025-02-05（上交）提出一种构建一个高质量、最小的数据集的系统的方法，LIMO仅817个样例，实现比NuminaMath（10w样例）显著的改进 全面的候选问题池：NuminaMath-Cot，AIME，MATH多阶段过滤：	使用Qwen2.5-Math-7B-Instruct，应用基线难度过滤器	用最先进的推理模型R1、DeepSeek-R1-Distill-Qwen">
<meta property="og:type" content="article">
<meta property="og:title" content="koori">
<meta property="og:url" content="http://eiszzz.github.io/2025/04/16/DP/index.html">
<meta property="og:site_name" content="koori">
<meta property="og:description" content="数据处理 LIMO：2025-02-05（上交）提出一种构建一个高质量、最小的数据集的系统的方法，LIMO仅817个样例，实现比NuminaMath（10w样例）显著的改进 全面的候选问题池：NuminaMath-Cot，AIME，MATH多阶段过滤：	使用Qwen2.5-Math-7B-Instruct，应用基线难度过滤器	用最先进的推理模型R1、DeepSeek-R1-Distill-Qwen">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-04-16T12:29:37.926Z">
<meta property="article:modified_time" content="2025-04-16T12:29:55.159Z">
<meta property="article:author" content="koori">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="koori" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">koori</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS 订阅"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="搜索"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://eiszzz.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-DP" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/04/16/DP/" class="article-date">
  <time class="dt-published" datetime="2025-04-16T12:29:37.926Z" itemprop="datePublished">2025-04-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>数据处理</p>
<p>LIMO：2025-02-05（上交）<br>提出一种构建一个高质量、最小的数据集的系统的方法，LIMO仅817个样例，实现比NuminaMath（10w样例）显著的改进</p>
<p>全面的候选问题池：NuminaMath-Cot，AIME，MATH<br>多阶段过滤：<br>	使用Qwen2.5-Math-7B-Instruct，应用基线难度过滤器<br>	用最先进的推理模型R1、DeepSeek-R1-Distill-Qwen-32B和Huang，仅保留即使这些最强大的模型在多次采样迭代后也低于某个阈值的问题<br>	保持多样性，战略采样技术，在数学领域和复杂度级别之间的平衡，同时避免概念冗余</p>
<p>评估框架：<br>	域内评估：包含美国数学邀请赛（AIME24）、MATH500（2021）、美国数学竞赛（AMC23）<br>	分布外（OOD）评估：<br>		多样化的数学竞赛：OlympiadBench（2024）<br>		新的多语言基准：2024中国高中数学联赛竞赛CHMath、2024中国高考GAOKAO、中国研究生入学考试KAOYAN，以及新开发的用于初等数学推理GradeSchool，（训练数据不含中文，引入一个额外的OOD纬度：未见过语言（中文）时的跨语言推理能力）<br>		多学科基准：数学（训练领域）以外的泛化能力，Miverva（本科水平的STEM），GPQA（2023）</p>
<p>性能指标：pass@1，零样本思维链，使用贪婪解码和一个单样本来评估正确性。对于包含少于50个问题的较小基准，生成16个样本，温度设置0.7，计算无偏pass@1指标。<br>最大输出长度32768个token，最大限度减少输出截断的可能性</p>
<p>s1k：2025-02-07（斯坦福）<a target="_blank" rel="noopener" href="https://www.selectdataset.com/dataset/90a705d5f1d56719f911781c9222b366">https://www.selectdataset.com/dataset/90a705d5f1d56719f911781c9222b366</a><br>背景：<br>	有限的计算资源，探索测试时扩展（test-time scaling）：在推理阶段增加计算资源来优化模型<br>困难与挑战：<br>	数据集质量与规模的平衡<br>	测试时扩展的可控性：例如如何精确地控制模型在测试时的思考时间，以及如何避免模型陷入无限循环或重复推理<br>	推理效率</p>
<p>s1k：（高质量、高难度、多样化、小规模高效）小型推理数据集，1000个推理问题及其详细的推理路径和答案<br>数据集构建：初始数据收集+最终样本筛选<br>	初始数据收集：从16个数据集收集了59029个问题，包括数学竞赛、奥林匹克学科、标准化考试问题。通过Google Gemini Flash Thinking API生成了详细的推理路径和答案<br>	最终样本筛选：<br>		质量筛选：去除格式错误和API错误的样本<br>		难度筛选：通过模型评估和推理路径长度筛选高难度问题<br>		多样性筛选：基于问题所属领域和推理路径长度进行加权采样，样本覆盖50个不同领域，包括数学、科学、逻辑</p>
<p>测试时扩展：<br>	顺序扩展：模型在推理时逐步生成解决方案，后续的计算依赖前面的结果<br>	并行扩展：同时，并通过某种机制（如投票或奖励模型）选择最佳答案<br>方法：预算强制，控制模型在推理时生成的token数量，来调整计算资源<br>	强制结束思考：token预设上限<br>	鼓励继续思考：插入“wait”等提示词，鼓励继续生成推理，直到token上限<br>方法的评估：关键指标<br>	控制性：能否精确精确的控制模型生成的token数<br>	扩展性：随着token数量增加，模型的准确性是否线性提升<br>	性能：在给定token下，模型能够达到的最高准确率</p>
<p>文中数据集：<br>	NuminaMATH<br>	OlympicArena：包含 4,250 个来自不同学科（如天文学、生物学、化学、计算机科学、地理学、数学和物理学）的奥林匹克竞赛问题。<a target="_blank" rel="noopener" href="https://www.selectdataset.com/dataset/cc1adaa0f2620de5acc9ae9ace7bcce8">https://www.selectdataset.com/dataset/cc1adaa0f2620de5acc9ae9ace7bcce8</a><br>	OmniMath<br>	AGIEval：20个官方、公开和高标准的入学和资格考试，如大学入学考试（如中国高考和美国SAT）、法学院入学考试、数学竞赛、律师资格考试和国家公务员考试。<a target="_blank" rel="noopener" href="https://www.selectdataset.com/dataset/83a6d0f0bb9b9222cca85478f4ae9797">https://www.selectdataset.com/dataset/83a6d0f0bb9b9222cca85478f4ae9797</a><br>	s1-prob：包含 182 个概率问题及其详细解法，覆盖了高级数学证明和复杂推理任务。该数据集的难度极高，适合用于训练模型解决专业级别的数学问题。<a target="_blank" rel="noopener" href="https://www.selectdataset.com/dataset/71fe2c6518309bb0c0030959d024f0bd">https://www.selectdataset.com/dataset/71fe2c6518309bb0c0030959d024f0bd</a><br>	s1-teasers：包含 23 个挑战性的数学谜题，通常用于量化交易面试。<a target="_blank" rel="noopener" href="https://www.selectdataset.com/dataset/195bbe3d56aa6b0ada403ff4c73b06a6">https://www.selectdataset.com/dataset/195bbe3d56aa6b0ada403ff4c73b06a6</a></p>
<p>Light- R1：2025-03-01（360）<br>deepseek-r1等长链推理模型通常参数庞大（671B），部署成本高昂，难以应用于边缘设备和实时应用。<br>Light-R1从零开始训练长链推理（Long Chain-of-Thought）模型，在资源受限等环境中实现高性能的数学推理能力。<br>主要贡献：<br>	提出一种从零开始训练长链推理模型的课程训练方法（Curriculum SFT和DPO）<br>	首次成功在14B参数的长链推理模型上实现强化学习（RL），RL对端侧模型训练的收益很大<br>	完全开源</p>
<p>步骤：<br>	从多个开源数据集（LIMO，OpenMathInstruct-2，OpenR1-Math-220k，OpenThoughts-114k、s1k-1.1，Omni-MATH，hendrycks_math）中收集了约100w数学题目，经过去重、格式标准化等预处理步骤，构建了一个高质量的种子数据集。<br>	利用DeepScaleR1.5B-Preview模型筛选出通过率低于阈值alpha的题目<br>	通过DeepSeek-R1-Distill-Qwen-32B模型进一步筛选出难度更高的题目，最终构建了一个包含76k题目的SFT阶段1数据集，和SFT阶段2数据集<br>	在SFT阶段1，模型通过76k数据集学习基础的推理能力<br>	在SFT阶段2，模型通过3k高难度数据集进一步优化推理能力</p>
<p>Light R1是以Qwen2.5-32B-Instruct为起点，该模型本身不具备长链推理能力，但通过课程训练逐步获得了强大的推理能力</p>
<p>强化学习（DPO，直接偏好优化）<br>	通过GRPO算法，模型在训练过程中不断调整输出，以获得更高的奖励分数<br>	采用360-LLaMA-Factory进行课程学习训练和DPO</p>
<p>AReaL-boba：2025-03-31（蚂蚁清华）<br>开源强化学习训练框架，基于SGLang推理框架，在数学上表现出色，7B模型在AIME基准测试中刷新同尺寸模型的分数记录。完全开源。</p>
<p>在32B模型尺寸上，发布AReaL-boba-SFT-200数据集以及相关训练脚本<br>基于R1-Distill-Qwen-32B，AReaL-boba使用仅仅200条数据，并以轻量级SFT方式，在AIME 2024上复现QwQ-32B的推理效果。（三个模型R1-Distill-Qwen-32B（72.6）、QwQ-32B（78.9）、AReaL-boba-SFT-32B（78.8））</p>
<p>Seed- Thinking-v1.5：2025-04-10<a target="_blank" rel="noopener" href="https://github.com/ByteDance-Seed/Seed-Thinking-v1.5%EF%BC%88%E5%AD%97%E8%8A%82%EF%BC%89%E3%80%90%E4%B8%8D%E5%BC%80%E6%BA%90%E3%80%91">https://github.com/ByteDance-Seed/Seed-Thinking-v1.5（字节）【不开源】</a><br>在AIME2024（数学竞赛）上，Seed-Thinking-v1.5（86.7，200B总参数，20B激活参数），DeepSeek-R1（79.8，671B总参数，37B激活参数），Gemini-2.5-pro（92.0），o3-mini-high（87.3）<br>由于AIME2024不能提供足够的区分度，构建了一个更具挑战的评估集，BeyondAIME，数据集中所有问题均由人类专家全新策划设计，最大限度地减少通过记忆或猜测解决问题的可能性。</p>
<p>数据<br>对于SFT训练，与传统的后训练数据不同，推理模型依赖CoT数据，即明确描述出分步推理过程。初步实验表明，过多的非CoT SFT数据会显著降低模型的探索能力。<br>对于RL训练，整合了四类数据：STEM问题、代码相关任务、逻辑推理以及诸如创意写作和对话之类的非推理数据。（在这些数据中，逻辑推理数据对 ARC-AGI 基准测试的性能提升贡献显著。数学数据展现出强大的泛化能力，并能在各种任务中带来广泛的性能提升。）</p>
<p>RL训练数据<br>具有确定答案的可验证问题+没有确定答案的不可验证问题。模型的推理能力主要来自第一部分，并且可以泛化到第二部分。<br>	可验证问题：主要包括配有答案的STEM问题、配备单元测试的编码问题、适合自动验证的逻辑推理。<br>		STEM学科数据：<br>		数十万个高质量、竞赛级的STEM学科问题（来源包括开源数据集、国内外公开竞赛和自有题库，涵盖数学（80%+）、物理和化学。<br>		数据清洗，首先剔除不完整、符号不一致或要求不明确的问题。<br>		对于剩余问题，用Doubao-Pro-1.5生成多个回答，模型获得woN分数（N个中最差）为1的问题被认为过于简单而被移除。<br>		最后，一些问题可能有不准确的参考答案，用SOTA推理模型为每个问题生成多个候选回答，如果模型的答案与参考答案不一致，但模型的输出显示高度的内部一致性，或者只涉及非常少量的推理Token，我们认为参考答案不正确。然后，（人工校检）人类专家对这些问题进行手动验证，以确保参考答案正确。<br>		数据增强，使数据更适合学习和评估，具体来说，将多项选择题转换为填空题或简答题格式，以消除猜测的可能性，并更好地评估推理能力。还修改了某些数学问题，以确保答案尽可能为整数。<br>		经过数据清洗和增强后，最终获得了10w个STEM学科问题的训练集。在训练过程中，用基于模型的Seed-Verifier来评估回答的正确性。<br>		概括：清洗，筛选难度，验证答案，增强</p>
<pre><code>	代码数据：
	来源知名编程竞赛题目，优先选择高质量、难度适中的问题
	每道题都包含：问题描述+单元测试+检查脚本
	过滤标准：要求题目具备实用性与挑战性
	训练中使用自建的代码纱箱系统进行离线验证，无需实时提交

	逻辑谜题数据：
	包含22种逻辑任务（数独、迷宫、24点）
	每种任务都有：自动数据生成器、自动答案验证器
	训练中动态调整题目难度（根据模型表现提升难度）
	总共生成1w道逻辑题目用于RL训练

不可验证问题：主要涵盖基于人类偏好进行质量评估的非推理任务，涉及创意写作、翻译、知识问答、角色扮演等。这些提示词源自Doubao-1.5 Pro的强化学习训练数据。
	数据处理：
		来自 Doubao-Pro 1.5 的 RL 数据。
		去除低质量样本：
			使用 SFT 模型生成多个答案，评估它们的得分方差。
			方差太小：说明样本没有多样性 → 丢弃。
		如果 reward 提升幅度太大：说明题目太简单 → 丢弃。
</code></pre>
<p>高级数学基准：BeyondAIME<br>	当前推理模型普遍使用 AIME（American Invitational Mathematics Examination） 作为数学能力评估标准。<br>	问题：<br>    * AIME 每年仅发布 30道题目，数据量小 → 易产生 高方差，难以稳定衡量模型间差距。<br>    * 部分题目难度不足，强模型之间拉不开差距。</p>
<pre><code>与数学专家合作，借鉴既定的竞赛形式来开发原创题目。通过结构性修改和情景重构，系统地改编现有的竞赛试题，确保不出现直接重复。此外，确保答案绝非平凡值（例如题目描述中明确提及的数字），以降低模型未经恰当推理便猜中正确答案的几率。
通过这一严格的筛选与整理过程，最终汇编成一套包含 100 道题目的测试集，每道题的难度级别等于或高于 AIME 中最难题目的难度。与 AIME 类似，所有答案保证为整数（且不受特定数值范围的限制），这简化并稳定了评估过程。
</code></pre>
<p>数据来源与构建方式<br>与数学专家合作：<br>    * 由人类专家专门设计新题，参考真实数学竞赛结构。<br>    * 保证题目有深度，能考察真正的推理能力。</p>
<ol>
<li>改编真实竞赛题目：<ul>
<li>通过结构重构与情境重塑避免重复。</li>
<li>例如：更换题设背景、调整数据、打乱条件顺序等。</li>
</ul>
</li>
<li>避免“猜答案”：<ul>
<li>所有答案保证为整数（简化评分）但不出现“显眼数字”。</li>
<li>目的：杜绝模型靠“模板记忆”或“猜数值”过关。</li>
</ul>
</li>
</ol>
<p>RL算法<br>	VAPO和DAPO：基于价值和无价值RL范式量身定制的两个不同框架<br>奖励模型<br>	可验证问题的奖励模型：两种渐进式的奖励建模解决方案：Seed-Verifier 和 Seed-Thinking-Verifier<br>	不可验证问题的奖励模型：配对生成式奖励模型（pairwise generative reward model），通过评估两个回复的优劣，并使用判定为“是”或“否”的概率作为最终的奖励分数。</p>
<p>方法<br>	SFT：先进行SFT<br>		30w可验证（提示词从RL训练集中随机抽样）+10w不可验证（源于用于Doubao-Pro 1.5的SFT数据）。构建了一个迭代工作流：人类专家用prompt或与模型交互式对话，积累数十个高质量的冷启动样本，训练一个具有长CoT的推理模型，作为助手。用Seed&#x3D;Verifier对这个推理模型执行拒绝采样，以产生详细的推理轨迹。<br>		在训练期间，每个实例被截断为3.2w个Token<br>		与从基础模型启动 RL 相比，SFT 模型产生的输出可读性更高，出现幻觉的情况更少，并且有害性也降低<br>	RL：-</p>
<p>实验结果<br>评测任务类别：</p>
<ul>
<li>数学：AIME、BeyondAIME</li>
<li>代码：Codeforces、LiveCodeBench、Aider Polyglot</li>
<li>科学推理：GPQA、SuperGPQA</li>
<li>Agentic Coding：SWE-bench verified</li>
<li>逻辑推理：ARC-AGI</li>
<li>知识与指令执行：SimpleQA、IFEval、Collie</li>
</ul>
<p>Skywork-OR1：2025-04-13<a target="_blank" rel="noopener" href="https://github.com/SkyworkAI/Skywork-OR1%EF%BC%88%E6%98%86%E4%BB%91%E4%B8%87%E7%BB%B4%EF%BC%89">https://github.com/SkyworkAI/Skywork-OR1（昆仑万维）</a><br>￼<br>数据处理：<br>step1：数据选择与预处理<br>	挑选高质量、有挑战性且可验证的数学与代码题目，用于RL<br>	选择标准：可验证性（排除了所有无法验证正确性的题目，如纯证明题（无标准答案）、缺乏测试用例的编程题），答案正确性（过滤掉数学题中存在错误或不合法答案的问题，编程中没有完备测试用例的样本），挑战性（提前用基础模型（如未强化学习前的模型）对每个问题生成多轮（N次）回答，然后排除全部答案都对（N&#x2F;N correct）和都错（0&#x2F;N correct）的问题<br>	数学数据来源：NuminaMath-1.5子集（amc_aime、olympiads、olympiads_ref、aops_forum、cn_contest、inequalities、number_theory），DeepScaleR，STILL-3 Preview RL数据集，Omni-MATH，AIME（2024年以前的历年真题）<br>	编程数据来源：LeetCode（真实高质量代码题目），TACO（带有完整结构与测试用例的代码任务）<br>step2：基于模型感知的难度评估（先用模型自己“试做一遍题”，再根据结果来评估题目的难度）<br>	数学题：每道题进行16次生成（N&#x3D;16）<br>	编程题：每道题生成8次（N&#x3D;8）<br>	每次生成使用：temperature&#x3D;1.0，最大上下文长度&#x3D;3.2w tokens<br>	难度判断：只保留答对部分的情况（这类题最能提供有用的训练信号，全对&#x2F;全错题目不利于优势估计<br>￼<br>目的与优势<br>只留下有分辨性的问题，提升训练数据的效能<br>确保 RL 的 advantage 计算成立，避免训练过程不稳定<br>为接下来的 Reward 函数设计和策略优化打下基础</p>
<p>step3：人类+大模型双重评审的数据质量评估<br>即使通过了前两步（筛选+难度评估），仍有不少题目存在质量问题，比如题干不完整、格式混乱、无关信息等。<br>Skywork 团队发现：<br>	许多数学题目 格式混乱、不完整，甚至无实际意义<br>	有些问题在模型评估中被标为“答对”，其实是模型凭经验猜对的<br>	高质量训练必须确保数据的清晰性、准确性和完整性<br>人类评估标准（手动抽样检查）：<br>	语言清晰：题干表达是否通顺易懂<br>	信息完整：是否包含了所有必需的条件和背景<br>	排版规范：数学符号是否正确、格式是否混乱<br>	无干扰内容：是否包含无意义的注释、乱码、翻译残留<br>LLM评审机制：<br>模型：Llama-3.3-70B-Instruct，Qwen2.5-72B-Instruct<br>自动流程：<br>	提出统一的评审prompt，请判断题目的质量（是否清晰、完整、规范等）<br>	每个问题由两个模型分别生成16个回答，总共32个投票<br>	统计判断结果：保留获得9票及以上肯定评价的题目<br>	清理掉剩下的低质量的问题，大约去掉1000-2000道数学题</p>
<p>Open-Reasoner-Zero：2025-03-31（阶跃星辰）<br>数据集<br>AIME（美国数学邀请赛，截至2023），MATH，Numina-Math，Tulu3 MATH，OpenR1-Math-220k，其他开源数据集<br>利用32B模型，找出模型在64次尝试中答对次数少于4次的问题，最终筛选出约1.3w个高难度问题，用于最后的收尾训练<br>策略核心：数量、多样性和质量<br>实验证明，当数据规模从7.5k增加道30k时，模型性能持续提升，没有任何饱和迹象。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://eiszzz.github.io/2025/04/16/DP/" data-id="cm9jwuh3m0000xoz33dux8nem" data-title="" class="article-share-link"><span class="fa fa-share">分享</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2025/04/15/RL/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title">RL Note</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/04/">四月 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/04/16/DP/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/04/15/RL/">RL Note</a>
          </li>
        
          <li>
            <a href="/2025/04/15/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 koori<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>